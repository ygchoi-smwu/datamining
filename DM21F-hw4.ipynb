{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DM21F-hw4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNMS9crjvXN04TBxiM4/+Os",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "ir",
      "display_name": "R"
    },
    "language_info": {
      "name": "R"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ygchoi-smwu/datamining/blob/main/DM21F-hw4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHiljQlBS1q-"
      },
      "source": [
        "# HW 4 -- Due 11/9 (화) 3pm\n",
        "\n",
        "_데이터마이닝 (2021-2 숙명여대 통계학과)_,  Last update at 2021-10-27 10:30pm\n",
        "\n",
        "### 조원 이름 (e.g. 2112345 김눈송, 2112346 김송이, 2112347 김통계)\n",
        "\n",
        "### 본 숙제의 최종 검토 겸 제출자: ___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRECGVkxTpss"
      },
      "source": [
        "## 0. 일러두기\n",
        "\n",
        "- 풀이&제출법\n",
        "    - **이론 문항**\n",
        "        - 풀이를 수기작성하여 하나의 PDF 파일로 수합합니다.\n",
        "    - **코딩 문항** \n",
        "        - 풀이는 본 ipynb notebook에 수행합니다.\n",
        "        - **사고과정과 핵심 수치는 text chunk를 만들어 답하되, 제시된 수치를 재현할 수 있는 code chunk를 같이 첨부**하십시오.\n",
        "        - **실행 결과가 기록된 ipynb만 채점합니다.** 제출 전 반드시 ‘[수정]-[모든 출력 지우기]’ 및 ‘[런타임]-[다시 시작 및 모두 실행]’!\n",
        "    - 문항마다 풀이자와 기여자를 기록합니다. (free rider 예방이 목적입니다. 사람 수에 제한은 없고 자율적 판단하에 기록하십시오) \n",
        "    - PDF 한개, ipynb 한개를 최종검토&제출자가 업로드합니다.\n",
        "- 이번 숙제에서 허용되는 라이브러리는 아래와 같으나, 그 외에 스스로 필요하다고 판단하면 **ISLR 7장까지 등장한 라이브러리, ggplot 및 dplyr는 사용 가능**합니다. 아래 code chunk를 실행시키세요.\n",
        "- 특별한 언급이 없으면 ISLR은 ISLR 2판을 지칭합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mN_g9JN0WEy2"
      },
      "source": [
        "library(stringr)\n",
        "install.packages(c(\"ISLR2\", \"FNN\", \"pROC\", \"glmnet\"))\n",
        "library(ISLR2)\n",
        "library(FNN)\n",
        "library(pROC)\n",
        "library(glmnet)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMHvDTcXPqQ-"
      },
      "source": [
        "## (이론) 1. ISLR #6.3\n",
        "\n",
        "- [b-e]는 직관적으로만 설명해도 된다. 설명이 핵심을 포함하고 있다면 길게 쓸 필요는 없다. 단, [a]는 직관적 설명 및 엄밀한 증명 모두 실시하라.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1ahW89lYzum"
      },
      "source": [
        "## (이론) 2. ISLR #6.5\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-gJLCczUq1S"
      },
      "source": [
        "## (이론) 3. ISLR #7.1\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRLOdkg3oabq"
      },
      "source": [
        "## (이론) 4. ISLR #7.3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLHRJ2gQ_o9i"
      },
      "source": [
        "## (이론) 5. ISLR #7.4\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rhvl8vkd_pMU"
      },
      "source": [
        "## (코딩) 6. \n",
        "\n",
        "(ISLR #6.10 변형) 일반적으로 모형에 편입된 변수의 수가 늘어나면 훈련 오류(training error)는 감소하나, 테스트 오류(test error)는 그렇지 않다. Simulation dataset을 생성하여 이 현상을 살펴 보자.\n",
        "\n",
        "* (a) 다음 조건을 만족시키는 표본(데이터셋)을 하나 생성하라. 표본크기는 $n=1,000$으로 하라. 자료행렬 $X$의 피처 개수는 $p=20$개가 되도록 하라. 이진형의 $Y$는 다음 로지스틱 선형모형을 만족시키도록 생성하라. \n",
        "$$\n",
        "\\mathbb{P}(Y =1 | X=x) = \\frac{\\exp ( \\beta_0 + x^T \\beta )}{ 1 + \\exp ( \\beta_0 + x^T \\beta )}\n",
        "$$\n",
        "단, true  $\\beta_0 \\in \\mathbb{R}$ 및 $\\beta \\in \\mathbb{R}^{20}$는 자유로이 결정하되, exact zero 성분이 일정 개수 존재하도록 하라.\n",
        "    - 힌트: HW3 9번의 데이터셋 생성 파트를 변형하라.\n",
        "* (b) 데이터셋을 표본크기 100의 훈련 세트와 표본크기 900의 테스트 세트로 분할하라.\n",
        "* (c) 훈련세트를 대상으로 **$\\ell_1$-규제된 이진 로지스틱 회귀분석 (라쏘 이진 로지스틱 회귀분석)**을  $\\lambda=2^{50}, 2^{49}, \\ldots,  2^{-48}, 2^{-49}$에 대하여 적합하라. `glmnet( .... , alpha=1, family='binomial')`이 필요할 것이다 (6장 강의노트 26, 27쪽 참고). 사용법은 매뉴얼을 참조하여라.\n",
        "\n",
        "$\\lambda$ 대응되는 적합계수(fitted coefficient)를 $(\\widehat{\\beta}_{0\\lambda}, \\widehat{\\beta}_{\\lambda})$라 하자. (단, $\\widehat{\\beta}_{0\\lambda} \\in \\mathbb{R}$, $\\widehat{\\beta}_{\\lambda} \\in \\mathbb{R}^p$)\n",
        "\n",
        "* (d) 다음을 적절히 시각화하라: $\\lambda$ vs. 적합된 모형계수 $\\widehat{\\beta}_{\\lambda}$의 nonzero 성분 개수 (``$\\widehat{\\beta}_{\\lambda}$의 자유도(degree of freedom, DF)''라 불린다).\n",
        "* (e) 다음을 적절히 시각화하라: $\\lambda$ vs. 적합된 모형의 훈련세트 오분류율 (training-set misclassification error)\n",
        "* (f) 다음을 적절히 시각화하라: $\\lambda$ vs. 적합된 모형의 테스트세트 오분류율 (test-set misclassification error).\n",
        "* (g)  $\\lambda$가 몇일 때 테스트세트 오분류율이 최소화되는가? 그에 대응하는 적합계수 $\\widehat{\\beta}_{\\lambda}$의 DF는 얼마인가? (e)와 비교하면 어떻게 다른가? 결과가 의미하는 바를 짧게 코멘트하여라. 만일 테스트세트 오분류율을 최소화하는 적합계수가 trivial하면 (intercept만 nonzero인 벡터거나 모든 성분이 nonzero인 벡터면), (a)번 문항으로 돌아가서 true $\\beta_0$ 및 $\\beta$를 고쳐라. 적당한 수준의 DF에서 테스트세트 오분류율이 최소화될 수 있도록 하라. \n",
        "* (h) 다음을 적절히 시각화하라: $\\lambda$ vs. 적합된 모형계수의 $\\ell_2$-추정오차(intercept 제외), 즉, $\\sqrt{ \\sum_{j=1}^p (\\widehat{\\beta}_{\\lambda j} - \\beta_j )^2}$.\n",
        "* (i) $\\lambda$가 몇일 때 위의 추정오차가 최소화되는가?  이 때의 $\\widehat{\\beta}_{\\lambda}$의 DF는 얼마인가? (g)에서 찾은 모형의 $\\lambda$ 및 자유도와 동일한가? 이 결과가 의미하는 바를 짧게 코멘트하여라. 일반적으로 prediction(새로운 input $x$에 대한 반응변수 예측)을 가장 잘 하는 모형과 estimation($\\beta$ 추정)을 가장 잘 하는 모형이 동일하겠는가? 본인의 생각을 짧게 코멘트하여라.\n",
        "* **유의사항** : 가독성 높은 시각화를 위하여 $\\lambda$축은 적당히 log-scaling하라. log2, log, log10 변환중 본인이 사용한 변환을 적시하라. ($\\because$ $\\lambda$는 등비수열이므로 변환없이 좌표축에 나타낼 경우 가독성이 떨어지고 인사이트를 얻기 어려울 수 있다.)"
      ]
    }
  ]
}